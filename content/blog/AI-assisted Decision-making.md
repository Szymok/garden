---
title: AI-assisted Decision-making
type: blog post
tags: 
aliases:
---
Years ago, Federal Express [couldn’t deliver packages on time.](https://fs.blog/bias-incentives-reinforcement/#:~:text=Munger%20talks%20about%20Federal%20Express,can%27t%20be%20done%20fast.) 

All packages were moved between airplanes at one central airport every night. The only problem was that the night shift wasn’t moving fast enough to get the job done—delays were common and customers were irate.

They’d tried everything they could to improve efficiency to no avail. Until they tried something new: they stopped paying by the hour. Instead, as soon as the night shift workers had completed the task of moving packages, they were allowed to go home with full pay.

Suddenly, packages were going out on time every night.

This story exemplifies one of investor Charlie Munger’s most famous adages: “Never, ever, think about something else when you should be thinking about the power of incentives.”

These sorts of Mungerisms are like catnip for business nerds. If you read through his speech, “[The Psychology of Human Misjudgment](https://fs.blog/great-talks/psychology-human-misjudgment/),” you’ll find all sorts of heuristics and mental models like this. It’s dense with them. Listening to (or reading) it, you get the sense that if you could just imbibe it—really inscribe it in your brain—you’d make such good decisions you could do anything in the world.

Unfortunately, that’s hard.

Over the last 10 years there’s been an explosion in the use of mental models and heuristics by entrepreneurs. Andrew Wilkinson, the CEO of Tiny—a $400 million market cap public holding company of technology businesses—[listened to Charlie Munger’s speech over and over again](https://twitter.com/awilkinson/status/1346124233060061186) on his way to work for a year.

Everyone wants to learn the latest behavioral economics trick, psychological insight, or lesson from science or philosophy that can help them make decisions.

The problem is: we can’t remember to apply them. We [make lists in Notion of our principles](https://every.to/superorganizers/how-a-pro-soccer-player-turned-vc-108624?sid=26218) and use Anki to note down mental models. But they end up being mostly abandoned.

ChatGPT changes this. It allows you to bring to bear the best of what other people have figured out every time you make a decision. Every heuristic or mental model you could ask for is already in its digital brain. All you have to do is remember to use it when you’re making decisions. 

I know because I’ve been using it. In order to show you how this works, I’m going to use ChatGPT to help the characters in a decisive moment in the movie _The Big Short_ make better decisions. Then I’ll show you how to deploy it in your own life.

## Selling shorts to Michael Burry

In _The Big Short_ (which is based on the true story of the traders who profited from the 2008 financial crisis)_,_ investor Michael Burry has a meeting at Goldman Sachs. He wants to short the housing market and has decided to bet $100 million. 

This looks like a good trade for the Goldman Sachs bankers. In order for this trade to lose money, millions of Americans would have to fail to pay their mortgages. This has never happened. There is no chance Burry is right. The bankers see dollar signs. 

They take the trade. They laugh as he leaves their office:

[![](https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2811/optimized_tH4ouuEaVjQMpfnpDOIoRFHarygxzVaOOvppPiChxH2rVLIjPiAujctM6JhDDKAN9PSEkOs5xH14RWVl_BDUWagwMso1TxQ0hKn2kNNu0QLoXOwq1avviWMIW4fR0EjTKt07QLgTFBMpGlJZfMRqIpY.png)](https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2811/optimized_tH4ouuEaVjQMpfnpDOIoRFHarygxzVaOOvppPiChxH2rVLIjPiAujctM6JhDDKAN9PSEkOs5xH14RWVl_BDUWagwMso1TxQ0hKn2kNNu0QLoXOwq1avviWMIW4fR0EjTKt07QLgTFBMpGlJZfMRqIpY.png?link=true)

We know how this ends: Burry’s right, and the bankers are just blind. 

Homebuyers, enticed by the prospect of cheap loans and the American dream, have been buying homes they can’t afford. Lenders, enticed by short-term profits, have been bending the rules of who is allowed to get a mortgage and originating loans to subprime homebuyers. Banks have been buying these mortgages, bundling them into securities, and selling them to investors. Bank employees are being rewarded with bonuses for the amount of securities they can sell, not their long-term performance. Credit rating agencies that are paid big bucks to sanction these securities look the other way, labeling them safe even though they contain loans that will likely blow up. The government and the media pump home ownership as the most important signal of success, and the cycle continues.

How can you help the Goldman Sachs bankers in this scene make a better decision? Let’s assume they’re smart enough to double-check their mental models before they sign away the keys to the kingdom. 

## Creating the psychological context for the players

The first thing you’ll want to do is have ChatGPT break down the psychology of the players in the situation. So all you have to do is ask:

[![](https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2811/optimized_-y0pDska7nudJ0FF88MspDhBzihMi7ssVVOeAQmCng6kaECGczGpVrCGz1uEEUXb-9YjP6225nDKef4DJ-nkJUc0VMoLsw4qREfKBhER4Wo6gTeJ-fXOugcBgSu2r74a1nJI-0bbNRb4HqIX9xs3XhU.png)](https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2811/optimized_-y0pDska7nudJ0FF88MspDhBzihMi7ssVVOeAQmCng6kaECGczGpVrCGz1uEEUXb-9YjP6225nDKef4DJ-nkJUc0VMoLsw4qREfKBhER4Wo6gTeJ-fXOugcBgSu2r74a1nJI-0bbNRb4HqIX9xs3XhU.png?link=true)

ChatGPT comes back with something pretty great. First it outlines Burry’s biography up to 2006:

[![](https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2811/optimized_C-zTiC-DbM8yPFgOjjgaikc2A2R3PVwSNqvfacBmu_PWzqP79YYl68-1IleG4RaGjAzmUJ4AThk-FQecMMI-k_4ao5SqeVD6BewqjzwuWF6QzColLd7jjYr-khIYla1asNLDJxtk65k7M1sWu1KBKJw.png)](https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2811/optimized_C-zTiC-DbM8yPFgOjjgaikc2A2R3PVwSNqvfacBmu_PWzqP79YYl68-1IleG4RaGjAzmUJ4AThk-FQecMMI-k_4ao5SqeVD6BewqjzwuWF6QzColLd7jjYr-khIYla1asNLDJxtk65k7M1sWu1KBKJw.png?link=true)

Then it summarizes that biography into a set of strengths and weaknesses:

[![](https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2811/optimized_1A3g81j8ZXkHB3uDzZXWLbvbt6Ml7H8KcLBFL4Tg0o90Z2eXnPBPlk9dNEcu5jg491D3KB_Fvm21nLHR9xsynn_MXXTJk-4Uh3oh3GpifLJJBWfqp3KEZmeKKY9JX6GyP6krdr2ofDcIF6sAFF6kSZE.png)](https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2811/optimized_1A3g81j8ZXkHB3uDzZXWLbvbt6Ml7H8KcLBFL4Tg0o90Z2eXnPBPlk9dNEcu5jg491D3KB_Fvm21nLHR9xsynn_MXXTJk-4Uh3oh3GpifLJJBWfqp3KEZmeKKY9JX6GyP6krdr2ofDcIF6sAFF6kSZE.png?link=true)

You might be tempted to think, “Isn’t this cheating?” Burry is a public figure, so obviously it’s going to be easier to create a summary for someone like that. 

In my experience, if you provide ChatGPT with a detailed set of observations about a person in your life, even if they aren’t famous, it will come up with a psychological profile that feels  accurate. For example, I recently met a founder who was in the middle of fundraising for their company and looking for me to angel invest. I fed my observations into ChatGPT to help me clarify my thinking:

[![](https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2811/optimized_SuxxghM_J_-NNCEuY_fpodOebx6Y7TIxGOf94H1i3KU05nDItR_pPKYADo-H2HHIKar6W8HgRuVSGh6ddSAK4kw0vsgjpbK2mWYIAVz2kt9BtKeQwuZyLyNIhK5V7g-GzdDC59KeWRbP9aW7nJ09SeI.png)](https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2811/optimized_SuxxghM_J_-NNCEuY_fpodOebx6Y7TIxGOf94H1i3KU05nDItR_pPKYADo-H2HHIKar6W8HgRuVSGh6ddSAK4kw0vsgjpbK2mWYIAVz2kt9BtKeQwuZyLyNIhK5V7g-GzdDC59KeWRbP9aW7nJ09SeI.png?link=true)

This person isn’t famous—and ChatGPT was able to put together a compelling psychological profile from just a few of my observations.

Once you’ve laid out the psychological profile of the key players in your decision, it’s time to ask ChatGPT to analyze the situation. 

## Analyzing the situation

We stan Munger’s list of mental models, and our Goldman Sachs scene is a perfect place to deploy them. All we have to do is set the context for ChatGPT and ask it to analyze using Munger’s speech:

[![](https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2811/optimized_97QhxM2jc64yN9BTuaDSWduILKFOnvVS6B0YjaCMQYpaEQqn20tVR13Sbx1Zu52MTUdgrrx4Oz6WJ7EG6v1ZQP2bYm4XQP4YdY3QVcBiJxgtuK3TYmglnryWvUXcWIK5pdHvhAqIxM8uX2gvXL-idWw.png)](https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2811/optimized_97QhxM2jc64yN9BTuaDSWduILKFOnvVS6B0YjaCMQYpaEQqn20tVR13Sbx1Zu52MTUdgrrx4Oz6WJ7EG6v1ZQP2bYm4XQP4YdY3QVcBiJxgtuK3TYmglnryWvUXcWIK5pdHvhAqIxM8uX2gvXL-idWw.png?link=true)

ChatGPT uses Munger’s list of misjudgments to help the hapless Sachsians analyze Burry. For example, it points out how incentives and confirmation bias might lead us to dismiss Burry as a quack without digging deeper.

If we ask it to analyze which misjudgment is most relevant given our knowledge of Burry’s strengths and weaknesses, here’s what it says:

[![](https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2811/optimized_c7aS-mJYHDWkasOBa8y0ODaSbMtcBfwp3gjmzBF2yTAz8AzxMj78m2kezaDuh8oBdE_aqCiPmjMaJKtlUxvzFU893oj0Dn3t1QzEPbO7A2W6bBNEh1ZZFVm8RVLtEHbkpshQY9RE6sS8ne8tDXBPEe8.png)](https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2811/optimized_c7aS-mJYHDWkasOBa8y0ODaSbMtcBfwp3gjmzBF2yTAz8AzxMj78m2kezaDuh8oBdE_aqCiPmjMaJKtlUxvzFU893oj0Dn3t1QzEPbO7A2W6bBNEh1ZZFVm8RVLtEHbkpshQY9RE6sS8ne8tDXBPEe8.png?link=true)

It picks up on the reason to believe Burry: he has a track record of analytical skill from long before _The Big Short_ days. It also detects why we might be hesitant to do that: his awkward demeanor makes it easy to dismiss him.

If the bankers in this scene had consulted ChatGPT, they might have been motivated to double-check their assumptions—and avoid such a bad trade.

## How to use AI in decision-making in your life

Using ChatGPT to analyze movie scenes may seem like a contrived example.

But in my experience, it’s actually quite good at analyzing situations by breaking down the motivations of key players and applying heuristics to help you unravel them. This is because [GPT-4 has human-level theory of mind](https://twitter.com/aibreakfast/status/1652505387860647936)—the ability to ascribe mental states to people—and it knows about all of the heuristics and mental models you might need in order to make good decisions.

If you want to apply this in your life, here are a few steps to get started:

#### **Use ChatGPT to break down decisions big and small**

Next time you’re facing a decision, talk to ChatGPT about it. Just provide it with as much context as you can, and ask it to help you break down the situation. 

#### **Use heuristics and mental models to deepen the analysis**

Make sure to bring in your favorite thinkers to help enrich your discussion. You can use Munger, Daniel Khaneman’s book _Thinking Fast and Slow_, Shane Parrish’s Farnam Street, or others. 

#### **Save things that work in Custom Instructions**

In the process of doing this, you’ll likely come up with mental models or heuristics that are particularly important for you. For example, I’ve identified that I’m [a little bit too agreeable in interpersonal situations](https://every.to/chain-of-thought/llms-can-simulate-personality-that-s-a-big-deal?sid=26219). I think this is likely driven by fear of feeling guilty about letting people down. I’ve found that asking myself the question, “What would I do if I wasn’t afraid of feeling guilty?” is a useful heuristic for understanding the situation from a less subjective angle. Ideally, once I’ve identified this, I’d like ChatGPT to remind me of it. This is what [Custom Instructions](https://every.to/chain-of-thought/using-chatgpt-custom-instructions-for-fun-and-profit?sid=26220) are for.

Custom Instructions allows you to tell ChatGPT how you want it to respond to your queries. In my Custom Instructions, I tell ChatGPT: “If I'm in a complex interpersonal situation, ask, ‘What would I do if I wasn't afraid of feeling guilty?’"

Now, whenever I ask ChatGPT for advice about situations involving other people, it starts by asking me what I would do if I weren't afraid of feeling guilty. I’ve found this helps me clarify things in my own mind and make better decisions as a result. 

If you play around with ChatGPT enough, you’ll probably find clarifying questions or heuristics that are equally helpful for you. 

So if you’re looking to make better decisions and want to learn how to incorporate more heuristics and mental models into your life, use ChatGPT. It’ll make a difference.