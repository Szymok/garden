---
raindrop_id: 725655202

---

# Metadata
Source URL:: https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41
Topics:: #chatgpt

---
# How I Won Singapore’s GPT-4 Prompt Engineering Competition

A deep dive into the strategies I learned for harnessing the power of Large Language Models (LLMs)

## Highlights
## Note

Oto podsumowanie strony, którą oglądasz:

- **Jak wygrałem singapurski konkurs na inżynierię promptów GPT-4** - artykuł autorstwa Sheila Teo, opublikowany w Towards Data Science, w którym opisuje swoje strategie i doświadczenia z wykorzystania dużych modeli językowych (LLM) do rozwiązywania zadań związanych z promptami.
- **CO-STAR** - ramka opracowana przez GovTech Singapore, która pomaga w strukturyzowaniu promptów, uwzględniając kontekst, cel, styl, ton, odbiorcę i format odpowiedzi. Pomaga to LLM zrozumieć zadanie i dostosować swoją odpowiedź do potrzeb użytkownika.
- **Delimitery** - specjalne znaki, które pomagają LLM odróżnić poszczególne części promptu i nadać im sens. Mogą być używane do sekcjonowania promptu, np. za pomocą znaków ###, &lt;&lt;&lt;, &gt;&gt;&gt; lub tagów XML. Pomaga to LLM zrozumieć, co jest ważne, a co nie.
- **System Prompts** - dodatkowy prompt, w którym podajemy instrukcje, jak LLM powinien się zachowywać. Jest to przydatne, gdy chcemy, aby LLM pamiętał te instrukcje przez całą rozmowę. System Prompts mogą zawierać definicję zadania, format wyjścia i ograniczenia, których LLM powinien przestrzegać.
- **Analiza danych za pomocą LLM** - możliwość wykorzystania LLM do analizy zbiorów danych bez użycia kodu lub wtyczek. LLM są dobre w wykrywaniu wzorców i trendów w danych, takich jak wykrywanie anomalii, klasteryzacja, analiza tekstowa lub analiza trendów. LLM nie są dobre w dokładnych obliczeniach matematycznych lub złożonej analizie statystycznej.