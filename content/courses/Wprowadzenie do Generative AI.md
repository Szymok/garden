---
title: Wprowadzenie do Generative AI
tags: 
aliases:
---
![](https://cloud.overment.com/1-1697475372.png)

# C01L01 â€” Wprowadzenie do Generative [[notes/uczenie maszynowe|AI]]

[[notes/Generatywna Sztuczna Inteligencja|Generatywna Sztuczna Inteligencja]] to obszar Sztucznej Inteligencji, skupiajÄ…cy siÄ™ na generowaniu np. tekstu, kodu, obrazÃ³w czy filmÃ³w. Trenowana na duÅ¼ych zestawach danych, jest zdolna do tworzenia nowych treÅ›ci. W rezultacie, Generatywna [[notes/uczenie maszynowe|AI]] (GenAI) moÅ¼e odgrywaÄ‡ ogromnÄ… rolÄ™ w procesach kreatywnych, w tym takÅ¼e w rozwijaniu oprogramowania. Obecnie jednym z najpopularniejszych przykÅ‚adÃ³w takich narzÄ™dzi sÄ… DuÅ¼e [[notes/Modele|Modele]] JÄ™zykowe ([[notes/Ustawienia LLM|Large Language Models]], LLM), takie jak rodzina modeli GPT od firmy OpenAI, na ktÃ³rej skupimy naszÄ… uwagÄ™ w nadchodzÄ…cych tygodniach.

W zwiÄ…zku z tym, Å¼e rozwÃ³j umiejÄ™tnoÅ›ci zwiÄ…zanych z wykorzystaniem LLM jest znacznie prostszy niÅ¼ nauka programowania, juÅ¼ na starcie masz ogromnÄ… przewagÄ™. Co podkreÅ›la [cytat Grega Brockmana, wspÃ³Å‚zaÅ‚oÅ¼yciela OpenAI](https://twitter.com/gdb/status/1692699977628242279).

![](https://cloud.overment.com/greg-d17870c5-8.png)

Jego stwierdzenie, Å¼e to osoby potrafiÄ…ce programowaÄ‡ mogÄ… mieÄ‡ najwiÄ™kszy wpÅ‚yw na [[notes/uczenie maszynowe|AI]], jest bardzo widoczny w praktyce. Jak niebawem siÄ™ przekonasz, **poÅ‚Ä…czenie GPT-3.5-Turbo oraz [[notes/GPT-4|GPT-4]] z kodem pozwoli Ci adresowaÄ‡ obecne ograniczenia modeli oraz poÅ‚Ä…czyÄ‡ je z zewnÄ™trznymi usÅ‚ugami, znacznie rozszerzajÄ…c dostÄ™pne moÅ¼liwoÅ›ci.** Aby to jednak byÅ‚o moÅ¼liwe, konieczne jest zrozumienie technologii, narzÄ™dzi oraz technik pracy, ktÃ³re pozwolÄ… Ci wyjÅ›Ä‡ znacznie dalej niÅ¼ rozmowa z ChatGPT. Z tego powodu niemal caÅ‚kowicie pominiemy zarÃ³wno ChatGPT, jak i narzÄ™dzia wspierajÄ…ce kodowanie (np. Github Copilot). W zamian **skupimy siÄ™ na bezpoÅ›redniej integracji OpenAI API z kodem aplikacji oraz dodatkiem w postaci automatyzacji**.

## Obecne moÅ¼liwoÅ›ci DuÅ¼ych Modeli JÄ™zykowych

[[notes/Modele|Modele]] JÄ™zykowe projektowane sÄ… z myÅ›lÄ…Â o tworzeniu treÅ›ci na podstawie wejÅ›ciowych danych oraz podÄ…Å¼aniem za instrukcjami w kontekÅ›cie czatu. W wyniku (prawdopodobnie) ogromnej skali danych wykorzystywanych do trenowania duÅ¼ych modeli jÄ™zykowych, mamy do czynienia ze zjawiskiem tzw. **emergencji** zwiÄ…zanym z [pojawianiem siÄ™ zachowaÅ„Â nieobecnych w przypadku mniejszych modeli](https://arxiv.org/abs/[[raindrop/LLM/2206|2206]].07682). PrzykÅ‚adem moÅ¼e byÄ‡Â zdolnoÅ›Ä‡ do tÅ‚umaczeÅ„ z jednego jÄ™zyka na inny, pomimo tego, Å¼e model nie byÅ‚Â dokÅ‚adnie do tego trenowany (ale oczywiÅ›cie miaÅ‚Â kontakt z tymi jÄ™zykami). 

ObecnoÅ›Ä‡ emergencji w LLMach moÅ¼e wyraÅºnie sugerowaÄ‡, Å¼e **wszystkie moÅ¼liwoÅ›ci modeli, z ktÃ³rymi obecnie mamy do czynienia, nie sÄ… nam jeszcze znane**. Tym bardziej, Å¼e mÃ³wimy tutaj o zachowaniach, ktÃ³re mogÄ… zaskakiwaÄ‡ takÅ¼e twÃ³rcÃ³w OpenAI. PrzykÅ‚adem jest fragment [[[notes/GPT-4|GPT-4]] Technical Report](https://cdn.openai.com/papers/gpt-4.pdf), omawiajÄ…cy **nieoczekiwany wzrost skutecznoÅ›ci w zadaniach "Hindsight Neglect"** zwiÄ…zanych z odrÃ³Å¼nianiem przewidywania od faktycznej odpowiedzi w obliczu znajomoÅ›ci rezultatu.

![](https://cloud.overment.com/gpt-4-paper-e0f2c1a3-0.png)

To jednak nie oznacza, Å¼e nie znamy zastosowaÅ„ duÅ¼ych modeli jÄ™zykowych oraz scenariuszy, w ktÃ³rych sprawdzajÄ… siÄ™ one wprost genialnie. Oto kilka przykÅ‚adÃ³w:

- **Wcielanie siÄ™ w rÃ³Å¼ne role niczym kameleon**, co jednoczeÅ›nie nadaje kontekst interakcji, dziÄ™ki ktÃ³remu uwaga modelu skupia siÄ™ na wybranym zagadnieniu (np. definicje wystÄ™pujÄ…ce w rÃ³Å¼nych dziedzinach sÄ… dziÄ™ki okreÅ›leniu roli asystenta postrzegane jednoznacznie).
- **Transformacje dostarczonych treÅ›ci**, np. tÅ‚umaczenia, korekty, analizy i podsumowania, uwzglÄ™dniajÄ…ce kontekst przetwarzanych dokumentÃ³w.
- **Parsowanie danych**, uwzglÄ™dniajÄ…c zadania, ktÃ³re sÄ… bardzo trudne do zrealizowania programistycznie, np. za pomocÄ… wyraÅ¼eÅ„ regularnych.
- **Odpowiadanie na pytania i generowanie treÅ›ci** na podstawie danych przekazanych jako kontekst zapytania.
- **Zadania zwiÄ…zane z programowaniem** uwzglÄ™dniajÄ… tworzenie, modyfikowanie, wyjaÅ›nianie, oraz debugowanie kodu.
- **Integracja z kodem aplikacji** i [[courses/Zastosowanie biznesowe|zastosowanie biznesowe]] czyniÄ… LLMi uÅ¼ytecznymi narzÄ™dziami, ktÃ³re pozwalajÄ… realizowaÄ‡ zadania zwiÄ…zane z przetwarzaniem jÄ™zyka naturalnego (eng. Natural Language Processing, [[notes/NLP|NLP]]).
- **PosÅ‚ugiwanie siÄ™ API**, w szczegÃ³lnoÅ›ci w kontekÅ›cie [Function Calling](https://openai.com/blog/function-calling-and-other-api-updates), oraz wersji modeli OpenAI wyspecjalizowanych w wyborze funkcji i generowaniu do nich parametrÃ³w.

Obecnie, ze wzglÄ™du na ograniczenia modeli, o ktÃ³rych powiemy za chwilÄ™, znacznie lepsze rezultaty otrzymamy w przypadku zadaÅ„ realizowanych **na podstawie dostarczonego kontekstu** i istniejÄ…cych danych. PrzykÅ‚adowo, zamiast oczekiwaÄ‡, Å¼e [[notes/GPT-4|GPT-4]] napisze dla mnie tekst, ktÃ³ry wÅ‚aÅ›nie czytasz, wykorzystujÄ™ go jedynie w celu korekty tego, co juÅ¼ napisaÅ‚em.

Podobnie wyglÄ…da to takÅ¼e w przypadku odpowiedzi na pytania, ktÃ³rych jakoÅ›Ä‡ jest **nieporÃ³wnywalnie lepsza** gdy dotyczÄ… one treÅ›ci doÅ‚Ä…czonych do zapytania, niÅ¼ gdy odpowiedÅº generowana jest wyÅ‚Ä…cznie na podstawie bazowej wiedzy modelu, ktÃ³ra obecnie czÄ™sto bywa nieaktualna.

Ostatecznie prawdopodobnie najwaÅ¼niejszÄ… z umiejÄ™tnoÅ›ci DuÅ¼ych Modeli JÄ™zykowych jest posÅ‚ugiwanie siÄ™ zewnÄ™trznymi usÅ‚ugami, narzÄ™dziami czy urzÄ…dzeniami. W praktyce mÃ³wimy tutaj o **generowaniu obiektÃ³w JSON**, ktÃ³re programistycznie sÄ… przesyÅ‚ane jako payload zapytania HTTP. NiemaÅ‚Ä… rolÄ™ peÅ‚ni takÅ¼e zdolnoÅ›Ä‡ do **podejmowania decyzji na temat tego, ktÃ³rÄ… z funkcji naleÅ¼y uruchomiÄ‡**, a nawet **planowania realizacji zadania, z uwzglÄ™dnieniem dostÄ™pnych narzÄ™dzi**. WÃ³wczas dochodzimy do koncepcji tzw. "Agenta" zdolnego do **autonomicznego (lub czÄ™Å›ciowo autonomicznego) realizowania zadaÅ„**, czego przykÅ‚adem jest chociaÅ¼by projekt [Aider](https://github.com/paul-gauthier/aider).

![ÅºrÃ³dÅ‚o: Github](https://cloud.overment.com/screencast-1693383991.svg)

PeÅ‚ne wykorzystanie tego, co oferujÄ… LLM-y, wymaga **poÅ‚Ä…czenia ich z kodem aplikacji**. Nie mÃ³wimy tutaj jedynie o poÅ‚Ä…czeniu z API OpenAI czy modelami OpenSource (np. LLaMA2). Do gry wchodzi tutaj projektowanie caÅ‚ej interakcji, uwzglÄ™dniajÄ…cej m.in.:

- **przetwarzanie rÃ³Å¼nych formatÃ³w danych** i ich organizacjÄ™ na potrzeby LLM (np. podziaÅ‚ na mniejsze fragmenty, wzbogacanie, opisywanie)
- **wykorzystywanie dynamicznego kontekstu** (eng. [Retrieval Augmented Generation](https://research.ibm.com/blog/retrieval-augmented-generation-[[notes/[[notes/Retrieval Augmented Generation (RAG)|Retrieval Augmented Generation (RAG)]]|RAG]]), RAG) oraz dÅ‚ugoterminowej pamiÄ™ci dziÄ™ki poÅ‚Ä…czeniu baz wektorowych (Pinecone / Qdrant / Supabase) oraz klasycznych silnikÃ³w wyszukiwania (Algolia / ElasticSearch). PrzykÅ‚adem moÅ¼e byÄ‡ [Quivr](https://github.com/stangirard/quivr).
- **projektowanie zÅ‚oÅ¼onych interakcji** wykraczajÄ…cych poza pojedyncze zapytania do modelu (np. w modelu [ReAct](https://react-lm.github.io/)), uwzglÄ™dniajÄ…cych korzystanie z rÃ³Å¼nych narzÄ™dzi.
- **Å‚Ä…czenie ze sobÄ… wielu modeli** wyspecjalizowanych w realizowaniu konkretnych zadaÅ„ (np. przetwarzaniu lub generowaniu grafik, audio czy wideo). PrzykÅ‚adem mogÄ… byÄ‡ usÅ‚ugi takie jak [ElevenLabs](https://www.elevenlabs.io) czy [Replicate](https://replicate.com).
- **trenowanie i fine-tuning modeli** w celu zaadresowania konkretnych rodzajÃ³w zadaÅ„ i sposobÃ³w ich wykonania, oraz ogÃ³lnego zwiÄ™kszenia skutecznoÅ›ci modelu w wybranych obszarach.

Projektowanie takich aplikacji wymaga takÅ¼e podejmowania szeregu dodatkowych zadaÅ„ zwiÄ…zanych z **monitorowaniem, moderacjÄ…, testowaniem i optymalizacjÄ…** systemu. MajÄ…c na uwadze to wszystko, zrozumiaÅ‚a powinna byÄ‡ teraz perspektywa Grega Brockmana, mÃ³wiÄ…ca o roli osÃ³b potrafiÄ…cych programowaÄ‡. Zdobycie programistycznych umiejÄ™tnoÅ›ci umoÅ¼liwiajÄ…cych wykorzystywanie duÅ¼ych modeli jÄ™zykowych jest nieporÃ³wnywalnie trudniejsze od jedynie rozszerzenia swojej wiedzy o techniki pracy z nimi.

## Obecne ograniczenia DuÅ¼ych Modeli JÄ™zykowych

Trenowanie LLM jest czasochÅ‚onne i wymaga przygotowania duÅ¼ych zestawÃ³w danych. To z tego powodu bazowa wiedza modeli OpenAI koÅ„czy siÄ™ w poÅ‚owie 2021 roku i nie zawiera caÅ‚ej dostÄ™pnej wiedzy, a jedynie wybrane fragmenty (chociaÅ¼ wedÅ‚ug promptu ChatGPT, wiedza uwzglÄ™dnia juÅ¼ dane do Stycznia 2022). Dodatkowo, sama charakterystyka modeli wiÄ…Å¼e siÄ™ z rÃ³Å¼nego rodzaju ograniczeniami, ktÃ³re po czÄ™Å›ci moÅ¼emy adresowaÄ‡ lub omijaÄ‡, a na inne nie mamy odpowiedzi.

> âš ï¸ PoniÅ¼sze przykÅ‚ady pochodzÄ… z narzÄ™dzia [Playground](https://platform.openai.com/playground), ktÃ³re omÃ³wimy bardziej szczegÃ³Å‚owo w kolejnych lekcjach. JeÅ›li chcesz skorzystaÄ‡ z niego juÅ¼ teraz, upewnij siÄ™, Å¼e jesteÅ› w trybie "Chat" i aktywny model to [[notes/GPT-4|GPT-4]].

**Ograniczenie bazowej wiedzy i halucynacje**

Brak dostÄ™pu do dowolnej wiedzy jest jednym z najwiÄ™kszych ograniczeÅ„ LLM, ktÃ³re wydaje siÄ™ wykluczaÄ‡ je z zastosowania np. podczas pracy z nowymi narzÄ™dziami, na temat ktÃ³rych model nie ma pojÄ™cia. Jest to jedna z gÅ‚Ã³wnych przyczyn tzw. **halucynacji modelu**, w wyniku ktÃ³rej odpowiedzi nie tylko nie zawierajÄ… poprawnych informacji, ale wyglÄ…dajÄ… tak, jakby byÅ‚y poprawne, przez co trudno na pierwszy rzut oka je zauwaÅ¼yÄ‡. PrzykÅ‚adowo, wedÅ‚ug GPT-4 najnowsza wersja macOS to Monterey (aczkolwiek taka odpowiedÅº nie zawsze siÄ™ pojawi, o czym powiem za chwilÄ™, omawiajÄ…c niedeterministycznÄ… naturÄ™ modeli).

![](https://cloud.overment.com/lie-de197701-9.png)

ğŸ”— [Zobacz przykÅ‚ad](https://platform.openai.com/playground/p/ygwvpyvpS61L6l7qdFvxqdBa?model=gpt-4)

IstniejÄ… rÃ³Å¼ne sposoby na zmniejszenie ryzyka takich sytuacji. Jednym z nich jest modyfikacja promptu (instrukcji dla modelu), aby podkreÅ›laÅ‚a prawdomÃ³wnoÅ›Ä‡ oraz bezpoÅ›rednie informowanie o braku dostÄ™pnej wiedzy.

![](https://cloud.overment.com/truthful-80bfaa92-a.png)

ğŸ”— [Zobacz przykÅ‚ad](https://platform.openai.com/playground/p/EbzMyCreijOAwU6WpXKVkoHH?model=gpt-4)

Do realizacji niektÃ³rych zadaÅ„ mamy moÅ¼liwoÅ›Ä‡ **dostarczenia dodatkowej wiedzy do modelu w postaci kontekstu zapytania.** JeÅ¼eli tylko jest to moÅ¼liwe, warto to zrobiÄ‡ oraz dodatkowo podkreÅ›liÄ‡, Å¼e generowane odpowiedzi muszÄ… wykorzystywaÄ‡ wiedzÄ™ z kontekstu. WÃ³wczas np. nasze pytanie o wersjÄ™ systemu jest poprawne, poniewaÅ¼ powiÄ…zana z nim informacja zostaÅ‚a doÅ‚Ä…czona do zapytania. 

![](https://cloud.overment.com/context-7e3f6047-d.png)

ğŸ”— [Zobacz przykÅ‚ad](https://platform.openai.com/playground/p/TktWqRIyaqDdhqKM2kN2VjGV?model=gpt-4)

Poza informacjÄ… o najnowszej wersji systemu, doÅ‚Ä…czyÅ‚em takÅ¼e aktualnÄ… datÄ™. ZrobiÅ‚em to nie bez powodu, poniewaÅ¼ podstawowa wersja modelu GPT-4 nie wie nawet "kiedy jest dziÅ›", o ile nie doÅ‚Ä…czymy tej informacji do kontekstu. JednoczeÅ›nie widzisz juÅ¼, Å¼e model Å›wietnie radzi sobie z **wykorzystywaniem informacji zawartych w kontekÅ›cie**, co otwiera przed nami rÃ³Å¼ne moÅ¼liwoÅ›ci oraz jasno sugeruje, Å¼e **poza bazowÄ… wiedzÄ… modelu, szczegÃ³lnie waÅ¼ne sÄ… takÅ¼e jego umiejÄ™tnoÅ›ci zwiÄ…zane z rozumowaniem, przetwarzaniem oraz transformacjÄ… treÅ›ci**.

**Ograniczenie dÅ‚ugoÅ›ci kontekstu**

Obecne LLM-y opierajÄ… siÄ™ na architekturze modelu Transformer, zaprezentowanej po raz pierwszy przez Google w 2017 roku w publikacji [Attention Is All You Need](https://arxiv.org/abs/1706.03762). WiÄ…Å¼e siÄ™ z niÄ… zarÃ³wno szereg moÅ¼liwoÅ›ci, jak i ograniczeÅ„. Jednym z nich jest limit dÅ‚ugoÅ›ci treÅ›ci przetwarzanej w danej chwili, obejmujÄ…cy zarÃ³wno **dane wejÅ›ciowe, jak i te generowane przez model**, ktÃ³ry okreÅ›la siÄ™ jako tzw. "Token Window".

![](https://cloud.overment.com/limit-fc93254f-3.png)

Limity rÃ³Å¼niÄ… siÄ™ w zaleÅ¼noÅ›ci od modeli. Obecnie mÃ³wimy o zakresie pomiÄ™dzy okoÅ‚o 4 a 16 tys. tokenÃ³w (fragmentÃ³w sÅ‚Ã³w). SÄ… jednak wyjÄ…tki w postaci np. modelu [Claude](https://claude.ai/), ktÃ³ry jest zdolny do pracy na 100 tys. tokenÃ³w w ramach pojedynczego zapytania.

Z dÅ‚ugoÅ›ciÄ… kontekstu wiÄ…Å¼Ä… siÄ™ jeszcze trzy dodatkowe wyzwania, z ktÃ³rymi bÄ™dziesz siÄ™ mierzyÄ‡ podczas pracy z duÅ¼ymi modelami jÄ™zykowymi. SÄ… to:

- **Koszty** zwiÄ…zane z przetwarzaniem i generowaniem tokenÃ³w, ktÃ³re szybko rosnÄ…, nawet na stosunkowo maÅ‚ej skali.
- **WydajnoÅ›Ä‡**, ktÃ³ra w duÅ¼ym stopniu jest uzaleÅ¼niona od liczby tokenÃ³w w ramach zapytania.
- **SkutecznoÅ›Ä‡**, ktÃ³ra wedÅ‚ug publikacji [Lost In The Middle](https://arxiv.org/pdf/2307.03172.pdf), spada w przypadku jednorazowego przetwarzania dÅ‚uÅ¼szych treÅ›ci.

Wszystko to prowadzi nas do prostego wniosku, mÃ³wiÄ…cego o tym, Å¼e warto projektowaÄ‡ swoje systemy tak, aby pracowaÅ‚y na moÅ¼liwie maÅ‚ym zestawie informacji **istotnych dla bieÅ¼Ä…cego zadania**. PrzykÅ‚ad poniÅ¼ej pokazuje jak nieprawidÅ‚owe dobranie kontekstu sprawiÅ‚o, Å¼e model nie byÅ‚ w stanie udzieliÄ‡ poprawnej odpowiedzi na pytanie (ale jego zachowanie jest zgodne z instrukcjÄ…). 

![](https://cloud.overment.com/wrong-e07d12c4-5.png)

ğŸ”—[Zobacz przykÅ‚ad](https://platform.openai.com/playground/p/csXdIoK1BetYGtvljtEAtFr7?model=gpt-4)

WÄ…tek pracy z tokenami i dÅ‚ugim kontekstem (np. prowadzeniem dÅ‚ugich rozmÃ³w czy przetwarzaniem dÅ‚ugich dokumentÃ³w) bÄ™dziemy jeszcze poruszaÄ‡ wielokrotnie w kolejnych lekcjach.Â Na razie zapamiÄ™taj jedynie, Å¼e **warto utrzymywaÄ‡ kontekst tak krÃ³tkim, jak to moÅ¼liwe**, o ile nie tracimy jego sensu.

**Niedeterministyczna natura**

Do prezentowanych przykÅ‚adÃ³w zadaÅ„ realizowanych przez GPT-4 doÅ‚Ä…czam linki kierujÄ…ce do Playground. JeÅ›li z nich skorzystasz to prawdopodobnie zauwaÅ¼ysz, Å¼e przy **ponownych prÃ³bach wykonywania dokÅ‚adnie tych samych instrukcji, wynik moÅ¼e ulegaÄ‡ zmianie**. Powodem jest **niedeterministyczna natura modeli**, ktÃ³ra w przeciwieÅ„stwie do **Pure Function** znanych z programowania funkcyjnego, nie daje nam pewnoÅ›ci, Å¼e dla tych samych danych uzyskamy dokÅ‚adnie takÄ… samÄ…Â odpowiedÅº.

W kolejnej lekcji wyjaÅ›niÄ™ Ci, skÄ…d dokÅ‚adnie to wynika. Tymczasem sprÃ³buj przejÅ›Ä‡ do poniÅ¼szego przykÅ‚adu i wykonaÄ‡ go kilkukrotnie (kasujÄ…c wiadomoÅ›Ä‡ wygenerowanÄ… przez asystenta). WÃ³wczas zauwaÅ¼ysz, Å¼e co jakiÅ› czas generowana odpowiedÅº bÄ™dzie rÃ³Å¼niÄ‡ siÄ™ od wczeÅ›niejszych. 

![](https://cloud.overment.com/nondeterministic-50751271-b.png)

ğŸ”— [Zobacz przykÅ‚ad](https://platform.openai.com/playground/p/NIf99Z2wfcCGFDnqdgsXK6Av?model=gpt-4)

Takie zachowanie jest bardzo niepoÅ¼Ä…dane w przypadku logiki aplikacji realizujÄ…cej okreÅ›lone zadania. Dodatkowe wyzwania pojawiajÄ… siÄ™ takÅ¼e na etapie wprowadzania modyfikacji do promptÃ³w oraz trudnych do przewidzenia danych wejÅ›ciowych (np. w przypadku czatbotÃ³w nie moÅ¼emy przewidzieÄ‡ tego, co wpisze uÅ¼ytkownik). Strategie radzenia sobie z tym problemem omÃ³wimy w pÃ³Åºniejszej czÄ™Å›ci AI Devs. Do tego czasu zapamiÄ™taj, Å¼e **moÅ¼esz jedynie sterowaÄ‡ zachowaniem modelu, ale nie masz pewnoÅ›ci, Å¼e wygenerowany rezultat zawsze bÄ™dzie zgodny z Twoimi zaÅ‚oÅ¼eniami**.

**Obliczenia i zadania logiczne**

Nowsze wersje modeli (np. GPT-4) [sÄ… coraz lepsze w zadaniach zwiÄ…zanych z obliczeniami oraz zÅ‚oÅ¼onymi zadaniami logicznymi](https://openai.com/research/improving-mathematical-reasoning-with-process-supervision). MajÄ…c jednak na uwadze ich niedeterministycznÄ… naturÄ™ oraz problemy zwiÄ…zane z halucynacjÄ…, raczej kiepskim pomysÅ‚em jest wykorzystywanie ich do przeprowadzania istotnych obliczeÅ„, szczegÃ³lnie na duÅ¼ych liczbach. Dlatego, jak widaÄ‡, GPT-4 podaje caÅ‚kowicie bÅ‚Ä™dny wynik dla zapytania: "821^5". 

![](https://cloud.overment.com/count-0dd0311b-7.png)

ğŸ”— [Zobacz przykÅ‚ad](https://platform.openai.com/playground/p/5eCXCJCRSLxeWP9wdbmiYN8z?model=gpt-4)

To jest przykÅ‚ad zadania, dla ktÃ³rego modele jÄ™zykowe po prostu **nie zostaÅ‚y stworzone**. Podobne problemy zaobserwujemy takÅ¼e przy przeliczaniu dat (np. GPT-4 nie zawsze wie, kiedy jest "za dwa tygodnie w Å›rodÄ™"), co nierzadko przydaje siÄ™ w praktycznych zastosowaniach LLM. Najlepszym sposobem na radzenie sobie w takich sytuacjach jest skorzystanie z narzÄ™dzi, ktÃ³re zostaÅ‚y stworzone z myÅ›lÄ… o takich zadaniach. PrzykÅ‚adem moÅ¼e byÄ‡ model WolframAlpha, ktÃ³ry bez najmniejszego problemu udziela poprawnej odpowiedzi na praktycznie dowolne obliczenia.

![](https://cloud.overment.com/wolfram-38154ac8-8.png)

WspomniaÅ‚em juÅ¼, Å¼e GPT-4 jest zdolne do posÅ‚ugiwania siÄ™Â API poprzez generowanie obiektÃ³w JSON. W przypadku Wolfram Alpha bezpÅ‚atny plan umoÅ¼liwia wykonanie 2000 zapytaÅ„ miesiÄ™cznie (co nierzadko wystarcza do prywatnych zastosowaÅ„) w ramach dostÄ™pu do API. MoÅ¼emy wiÄ™c stworzyÄ‡ prompt, ktÃ³rego zadaniem bÄ™dzie **przeanalizowanie zapytania uÅ¼ytkownika i pobranie z niego informacji na temat zadania, ktÃ³re zostanie zrealizowane przez inny model**. ZwrÃ³cona odpowiedÅº moÅ¼e albo zostaÄ‡ bezpoÅ›rednio zwrÃ³cona uÅ¼ytkownikowi albo **sparafrazowana w czytelny sposÃ³b**. DokÅ‚adnie na tej samej zasadzie moÅ¼emy wyposaÅ¼yÄ‡ GPT-4 w inne narzÄ™dzia, ktÃ³re bÄ™dÄ… w stanie adresowaÄ‡ jego sÅ‚abe strony. O konkretach pomÃ³wimy jednak przy okazji lekcji na temat Function Calling.

## Praktyczne zastosowanie LLM w kontekÅ›cie prywatnym

WymieniaÅ‚em ogÃ³lne zastosowania DuÅ¼ych Modeli JÄ™zykowych, jednak moÅ¼e nie byÄ‡ jasne, jak przekÅ‚adajÄ… siÄ™ one na faktyczne zastosowanie w codziennym Å¼yciu. PominÄ™ jednak te najbardziej oczywiste przykÅ‚ady, ktÃ³re na co dzieÅ„ widzimy w Internecie, i skupiÄ™ siÄ™ na tych, ktÃ³re jednoznacznie wynikajÄ… z **poÅ‚Ä…czenia programowania z AI**.

### BezpoÅ›rednia integracja komputera i API

StaÅ‚y dostÄ™p do moÅ¼liwoÅ›ci oferowanych przez LLMy, a takÅ¼e przypisanie skrÃ³tÃ³w klawiszowych do wybranych zadaÅ„, pozwala znacznie przyspieszyÄ‡ pracÄ™. Zintegrowanie, na przykÅ‚ad GPT-4, opiera siÄ™ na poÅ‚Ä…czeniu z OpenAI API, ktÃ³re moÅ¼e byÄ‡ realizowane poprzez aplikacje takie jak: **Keyboard Maestro lub Shortcuts (macOS), AutoHotkey (macOS / Windows) rozwijana przeze mnie publiczna wersja aplikacji Alice (macOS / Windows).** Alternatywnie, moÅ¼na skorzystaÄ‡ z ulubionego komunikatora (np. Slack / Telegram / Discord) i zbudowaÄ‡ prostego bota umoÅ¼liwiajÄ…cego rozmowÄ™ z modelami GPT. 

![](https://cloud.overment.com/translate-1691593854.gif)

WartoÅ›Ä‡ takiej integracji charakteryzuje siÄ™ tym, Å¼e roÅ›nie z czasem. Nie mÃ³wimy tutaj wyÅ‚Ä…cznie o prostych zapytaniach kierowanych do OpenAI, ale o uwzglÄ™dnieniu wÅ‚asnych rozszerzeÅ„, ktÃ³re zwiÄ™kszajÄ… moÅ¼liwoÅ›ci modelu oraz dopasowujÄ… go do naszych potrzeb. Widoczny na powyÅ¼szej animacji prosty przykÅ‚ad tÅ‚umaczeÅ„, moÅ¼e zostaÄ‡ dopasowany tak, aby utrzymywaÅ‚ ton charakterystyczny dla naszego stylu wypowiedzi. Daje to modelowi znacznie wiÄ™kszÄ… przewagÄ™ nad korzystaniem z narzÄ™dzi takich jak Deepl, a takÅ¼e pozwala na uzupeÅ‚nianie naszych wypowiedzi, wzbogacajÄ…c je lub upraszczajÄ…c. 

Drugim zastosowaniem wÅ‚asnej integracji z LLM jest API, dziÄ™ki ktÃ³remu moÅ¼emy na przykÅ‚ad dodawaÄ‡ rÃ³Å¼ne informacje do pamiÄ™ci dÅ‚ugoterminowej. Jeden z przykÅ‚adÃ³w umoÅ¼liwia czytanie i zapamiÄ™tywanie treÅ›ci stron dodanych do tablicy Feedly, ktÃ³re nastÄ™pnie mogÄ… byÄ‡ wykorzystane w trakcie rozmowy z asystentem AI.

![](https://cloud.overment.com/feedly-3ca144b8-2.png)

### PoÅ‚Ä…czenie z Internetem i Wyszukiwarkami

GPT-4 domyÅ›lnie nie posiada dostÄ™pu do Internetu. NarzÄ™dzia takie jak Bing Chat czy Perplexity to oferujÄ…, jednak nie mamy wiÄ™kszego wpÅ‚ywu na sposÃ³b przetwarzania treÅ›ci oraz dostÄ™pu do informacji. Stworzenie prostej wÅ‚asnej integracji, ktÃ³ra pozwala na wyszukiwanie oraz czytanie treÅ›ci stron, jest stosunkowo Å‚atwe dziÄ™ki [[notes/Langchain|LangChain]] oraz poÅ‚Ä…czeniu z Puppeteer czy Playwright. DostÄ™p do wynikÃ³w wyszukiwania moÅ¼emy uzyskaÄ‡ poprzez [SerpAPI](https://serpapi.com) lub prosty skrypt dziaÅ‚ajÄ…cy na przykÅ‚ad w poÅ‚Ä…czeniu z DuckDuckGo.  

![](https://cloud.overment.com/reading-b5cf5865-8.png)

Efekt pozornie niewiele rÃ³Å¼ni siÄ™ od tego, ktÃ³ry moÅ¼emy osiÄ…gnÄ…Ä‡ na przykÅ‚ad w ChatBing. Jednak w praktyce daje nam to szereg przewag, takich jak: 

- CaÅ‚kowita kontrola nad promptami odpowiedzialnymi za przetwarzanie caÅ‚ej treÅ›ci strony lub jej wybranych fragmentÃ³w
- MoÅ¼liwoÅ›Ä‡ zapisania historii konwersacji w celu jej wyszukiwania podczas przyszÅ‚ych rozmÃ³w
- Zestawianie tych informacji z wÅ‚asnÄ… bazÄ… wiedzy, co prezentuje przykÅ‚ad poniÅ¼ej

![](https://cloud.overment.com/extending-d0ccc003-8.png)

Podobne rezultaty osiÄ…gniemy w ostatnim module naszego programu, w ktÃ³rym zaprojektujemy mechaniki osobistego asystenta. JeÅ¼eli nie planujesz budowaÄ‡ takich integracji, to wspomniane Perplexity jest obecnie najlepszym narzÄ™dziem oferujÄ…cym dostÄ™p do Internetu oraz niespotykanie szybkie generowanie wynikÃ³w. Stworzenie wÅ‚asnego API pozwala jednak na znacznie wiÄ™kszÄ… personalizacjÄ™ oraz planowanie dziaÅ‚aÅ„ wykonywanych w tle (na przykÅ‚ad obserwowanie wybranych stron www). 

### Hiper-personalizacja dziÄ™ki dÅ‚ugoterminowej pamiÄ™ci

W zwiÄ…zku z tym, Å¼e do kontekstu zapytania GPT-4 moÅ¼emy doÅ‚Ä…czyÄ‡ rÃ³Å¼ne informacje, naturalnym wydaje siÄ™ poÅ‚Ä…czenie ich z naszymi bazami wiedzy oraz rozmawianie z ich treÅ›ciÄ…. Kluczowym aspektem stajÄ… siÄ™ tutaj **organizacja oraz wyszukiwanie informacji**, ktÃ³re mogÄ… byÄ‡ dynamicznie wstrzykiwane do kontekstu i wykorzystane w trakcie generowania odpowiedzi. 

ZÅ‚oÅ¼onoÅ›Ä‡ takich systemÃ³w roÅ›nie wraz z rozbudowÄ… bazy wiedzy. Jak juÅ¼ pokazaÅ‚em, umieszczenie w kontekÅ›cie zbyt wielu informacji lub ich bÅ‚Ä™dne dopasowanie negatywnie wpÅ‚ynie na zachowanie modelu i tym samym na wartoÅ›Ä‡ udzielonej odpowiedzi. PoniÅ¼sze pytanie o link do narzÄ™dzia podobnego do Ray.so sprawiÅ‚o, Å¼e przeszukana zostaÅ‚a baza zawierajÄ…ca **listÄ™ zasobÃ³w/linkÃ³w**. DziÄ™ki dopasowaniu sÅ‚Ã³w kluczowych oraz zastosowaniu bazy wektorowej i similarity search, moÅ¼liwe byÅ‚o odnalezienie rekordu, ktÃ³ry najbardziej pasowaÅ‚ do przesÅ‚anego zapytania.

![](https://cloud.overment.com/integration-150734ca-8.png)

MoÅ¼esz jednak uznaÄ‡, Å¼e takie wyszukiwanie moÅ¼e zostaÄ‡ zrealizowane prostym dopasowaniem sÅ‚Ã³w kluczowych i nie potrzebujemy tutaj AI. SytuacjÄ™ zmienia jednak kolejny przykÅ‚ad, w ktÃ³rym wyjaÅ›nienie cytatu zostaÅ‚o **zestawione z wiedzÄ… na mÃ³j temat**, czyniÄ…c wiadomoÅ›Ä‡ bardziej personalnÄ… i rezonujÄ…cÄ….

![](https://cloud.overment.com/explain-574b3532-b.png)

Interakcja z GPT-4, ktÃ³ry posiada dostÄ™p do wiedzy na nasz temat (na przykÅ‚ad na podstawie wczeÅ›niejszych interakcji), pokazuje prawdziwy potencjaÅ‚ tej technologii. Odpowiednio zaprojektowany system moÅ¼e nawet prowadziÄ‡ nas przez proces zdobywania konkretnych umiejÄ™tnoÅ›ci czy nawykÃ³w, opierajÄ…c siÄ™ na naszym dotychczasowym postÄ™pie. 

### PoÅ‚Ä…czenie z usÅ‚ugami i urzÄ…dzeniami

Ostatnim z waÅ¼niejszych zastosowaÅ„ prywatnych jest poÅ‚Ä…czenie z rÃ³Å¼nymi usÅ‚ugami, na przykÅ‚ad listÄ… zadaÅ„, kalendarzem, aplikacjÄ… do notatek, pocztÄ… e-mail, komunikatorami czy wÅ‚asnymi skryptami realizujÄ…cymi rÃ³Å¼ne zadania. W rozmowie poniÅ¼ej, **rozpoznano wydanie polecenia**, ktÃ³re nastÄ™pnie zostaÅ‚o skojarzone z **akcjÄ… dodawania zdarzeÅ„ do kalendarza**. W zwiÄ…zku z tym, model wygenerowaÅ‚ obiekt JSON opisujÄ…cy wprowadzane zmiany oraz odpowiedÅº potwierdzajÄ…cÄ… wykonanie zadania. 

![](https://cloud.overment.com/calendar-ce767b2d-e.png)

WyposaÅ¼enie modeli jÄ™zykowych w narzÄ™dzia pozwala na zwiÄ™kszenie ich uÅ¼ytecznoÅ›ci oraz zredukowanie halucynacji. DoskonaÅ‚ym potwierdzeniem tych sÅ‚Ã³w jest [publikacja na temat ToolLM](https://arxiv.org/abs/2307.16789) â€” modelu wyspecjalizowanego w posÅ‚ugiwaniu siÄ™ API na podstawie dokumentacji. 

Realizacja takich integracji jest moÅ¼liwa poprzez poÅ‚Ä…czenie wspomnianego juÅ¼ Function Calling oraz logiki aplikacji odpowiadajÄ…cej za faktyczne poÅ‚Ä…czenie z usÅ‚ugami lub urzÄ…dzeniami. Co ciekawe, w tym ostatnim obszarze, genialnie sprawdzajÄ… siÄ™ rozwiÄ…zania no-code/low-code, ktÃ³re pozwalajÄ… szybko iterowaÄ‡ oraz Å‚Ä…czyÄ‡ siÄ™ z rÃ³Å¼nymi usÅ‚ugami, [co szczegÃ³Å‚owo omawia ta publikacja](https://arxiv.org/abs/2304.08103).

## Praktyczne zastosowanie LLM w kontekÅ›cie zawodowym i biznesowym

DuÅ¼e Modele JÄ™zykowe sprawdzajÄ… siÄ™ nie tylko w wymiarze prywatnym, ale przede wszystkim biznesowym. NaleÅ¼y jednak nadal mieÄ‡ na uwadze fakt, Å¼e obecnie na rynku nie ma jeszcze dojrzaÅ‚ych narzÄ™dzi, frameworkÃ³w czy wzorcÃ³w projektowych pozwalajÄ…cych na swobodne rozwijanie aplikacji Å‚Ä…czÄ…cych kod z LLM. Doskonale obrazuje to slajd z prezentacji [State of GPT](https://youtu.be/bZQun8Y4L2A?t=2244), mÃ³wiÄ…cy m.in. o:

- Wykorzystywaniu w **niekrytycznych** obszarach pod nadzorem czÅ‚owieka
- Zastosowaniu jako ÅºrÃ³dÅ‚o inspiracji lub sugestii
- Preferowaniu copilotÃ³w / asystentÃ³w niÅ¼ autonomicznych rozwiÄ…zaÅ„

![](https://cloud.overment.com/state-a10c5ebd-4.png)

MÃ³wiÄ…c o tym bardziej obrazowo, GPT-4 **nie jest jeszcze w peÅ‚ni gotowy do zastosowaÅ„ produkcyjnych** i obecnie sprawdzi siÄ™ jako ich **uzupeÅ‚nienie** lub do prywatnych zastosowaÅ„. GÅ‚Ã³wne argumenty, ktÃ³re potwierdzajÄ… takie nastawienie to: 

- Brak narzÄ™dzi do sterowania zachowaniem modelu, na ktÃ³rych moÅ¼na polegaÄ‡. WynikajÄ… z tego rÃ³Å¼nego rodzaju problemy, siÄ™gajÄ…ce nawet w obszar bezpieczeÅ„stwa, poniewaÅ¼ model moÅ¼e podejmowaÄ‡ dziaÅ‚ania niezgodne z zaÅ‚oÅ¼eniami. PrzykÅ‚adem moÅ¼e byÄ‡ wygenerowanie przez chatbota nieprawdziwej odpowiedzi.
- DostÄ™pnoÅ›Ä‡ API nadal jest niewystarczajÄ…ca do biznesowych zastosowaÅ„ wymagajÄ…cych wysokiego SLA. Istnieje jednak (trudno dostÄ™pna w EU) opcja dostÄ™pu do modeli OpenAI w ramach Microsoft Azure lub poprzez [ChatGPT Enterprise](https://openai.com/blog/introducing-chatgpt-enterprise) (wymagajÄ… skali powyÅ¼ej $10 000 wedÅ‚ug mojej rozmowy z OpenAI. Nie wiem jednak, czy jest to indywidualna oferta czy ogÃ³lna reguÅ‚a).

Sam posiadam rÃ³Å¼ne narzÄ™dzia wykorzystujÄ…ce modele OpenAI, ktÃ³re pomagajÄ… mi w pracy, ale absolutnie nie nadajÄ… siÄ™ do udostÄ™pnienia innym, nietechnicznym uÅ¼ytkownikom. Jako programista, dysponujÄ™ wiedzÄ… na temat pracy z modelami oraz w razie potrzeby mogÄ™ swobodnie wprowadzaÄ‡ potrzebne zmiany w promptach oraz w kodzie. W przypadku produkcyjnych zastosowaÅ„, nie byÅ‚oby to juÅ¼ tak proste i przykÅ‚adowo, utrzymanie stabilnoÅ›ci aplikacji stanowiÅ‚oby doÅ›Ä‡ duÅ¼e wyzwanie (aczkolwiek, w praktyce zaleÅ¼y to od realizowanego projektu).

Naturalnie, **nie oznacza to, Å¼e zastosowanie GPT-4 w niektÃ³rych obszarach produkcyjnych nie jest moÅ¼liwe**. W praktyce jednak, niemal wszystkie obecnie dostÄ™pne na rynku produkty, przy bliÅ¼szym poznaniu, okazujÄ… siÄ™ niedopracowane i, co gorsza, nie realizujÄ… oferowanej wartoÅ›ci. Ostatecznie, nie powinno stanowiÄ‡ to duÅ¼ego zaskoczenia, poniewaÅ¼ mÃ³wimy o zastosowaniu technologii, ktÃ³ra zaczÄ™Å‚a zdobywaÄ‡ popularnoÅ›Ä‡ kilka miesiÄ™cy temu. WiÄ™cej na temat zastosowaÅ„ produkcyjnych w kontekÅ›cie biznesowym powiemy w lekcjach zwiÄ…zanych z automatyzacjÄ… poÅ‚Ä…czonÄ… z AI oraz podczas projektowania wÅ‚asnego asystenta AI.

### AI oraz automatyzacja procesÃ³w, organizacja i dostÄ™p do wiedzy, rozwÃ³j produktÃ³w i ich funkcjonalnoÅ›ci

LLM majÄ… duÅ¼y potencjaÅ‚ w kontekÅ›cie zastosowania ich w obszarze automatyzacji procesÃ³w biznesowych oraz rozwoju produktÃ³w. W praktyce jednak, **bardzo Å‚atwo jest zbudowaÄ‡ prototyp**, a dojÅ›cie do dziaÅ‚ajÄ…cego produktu zajmuje duÅ¼o czasu. Poza wymienionymi przed chwilÄ… wyzwaniami, wdroÅ¼enie rozwiÄ…zaÅ„ AI do istniejÄ…cych procesÃ³w wiÄ…Å¼e siÄ™ z podjÄ™ciem wymagajÄ…cych dziaÅ‚aÅ„. Mowa tutaj miÄ™dzy innymi o:

- Poznanie samej technologii przez zespÃ³Å‚. Zdobywanie wiedzy przez top-level management oraz osoby odpowiedzialne za faktyczne wdroÅ¼enie AI zajmuje czas. Obecnie na rynku brakuje wiedzy i jakoÅ›ciowych szkoleÅ„ kierowanych nie tylko dla programistÃ³w. Poza dostÄ™pnoÅ›ciÄ… wiedzy, do gry wchodzi jeszcze czas potrzebny na faktyczne zdobycie umiejÄ™tnoÅ›ci oraz pÃ³Åºniejsze praktyczne doÅ›wiadczenie.
- Zazwyczaj wdroÅ¼enie rozwiÄ…zaÅ„ AI wymaga zgromadzenia i przetworzenia rÃ³Å¼nego rodzaju danych (bazy wiedzy, dokumentacje, opisy procesÃ³w, standardy itd.), co jest Å¼mudnym i czasochÅ‚onnym zajÄ™ciem. Zwykle wyzwanie stanowi tutaj **rozproszenie danych w rÃ³Å¼nych usÅ‚ugach oraz formatach**. Np. odczytanie danych z dokumentÃ³w PDF, nawet w poÅ‚Ä…czeniu z AI, nie jest proste. Po zgromadzeniu danych konieczne jest ich przetworzenie i przygotowanie na potrzeby modeli jÄ™zykowych (kategoryzacja, tagowanie, wzbogacanie, dzielenie na mniejsze fragmenty) w sposÃ³b umoÅ¼liwiajÄ…cy ich aktualizacjÄ™. Nierzadko mÃ³wi siÄ™, Å¼e wdroÅ¼enie AI to przede wszystkim praca zwiÄ…zana z organizacjÄ…Â danych. 
- JuÅ¼Â na etapie developmentu pojawiajÄ…Â siÄ™Â wyzwania zwiÄ…zane z kosztami usÅ‚ug dostawcÃ³w zarÃ³wno modeli (np. OpenAI) jak i zewnÄ™trznych API (np. Pinecone). Rozliczanie w modelu uzaleÅ¼nionym od zuÅ¼ycia generuje dodatkowe koszty dla kaÅ¼dej osoby zaangaÅ¼owanej w development. Optymalizacja zajmuje czas i wymaga wiedzy zwiÄ…zanej nie tylko z projektowaniem promptÃ³w, ale takÅ¼e optymalizacji mechanizmÃ³w wyszukiwania czy przetwarzania treÅ›ci.
- Aplikacja dziaÅ‚ajÄ…ca na produkcji wymaga staÅ‚ego monitorowania oraz podjÄ™cia dodatkowych krokÃ³w zwiÄ…zanych z moderowaniem danych wejÅ›ciowych pod kÄ…tem zgodnoÅ›ci np. z politykÄ…Â OpenAI oraz zaÅ‚oÅ¼eniami naszego oprogramowania (np. nie chcemy, aby czatbot przyjmujÄ…cy zamÃ³wienia byÅ‚ w stanie rozmawiaÄ‡ na inne tematy). Do tego dochodzi takÅ¼e moÅ¼liwoÅ›Ä‡ minimalizowania ryzyka wygenerowania niepoprawnych odpowiedzi (halucynacji modelu) oraz obsÅ‚uga bÅ‚Ä™dÃ³w i przypadkÃ³w brzegowych.
- RozwÃ³j aplikacji wykorzystujÄ…cych LLM generuje takÅ¼e problemy w zwiÄ…zku z wprowadzaniem modyfikacji i budowaniem nowych funkcjonalnoÅ›ci. W przeciwieÅ„stwie do kodu, nie mamy tutaj jeszcze sensownych narzÄ™dzi umoÅ¼liwiajÄ…cych testowanie promptÃ³w w celu upewnienia siÄ™, Å¼e aktualizacja nie wprowadza regresji w aplikacji. Problem ten zaczyna byÄ‡ adresowany poprzez narzÄ™dzia takie jak [LangSmith](https://smith.langchain.com/) (jest jeszcze na bardzo wczesnym etapie rozwoju).

Podstawowe ÅºrÃ³dÅ‚a na temat zastosowaÅ„ produkcyjnych moÅ¼na znaleÅºÄ‡ [w dokumentacji OpenAI](https://platform.openai.com/docs/guides/safety-best-practices). Jest to jednak wierzchoÅ‚ek gÃ³ry lodowej, dlatego w miarÄ™ moÅ¼liwoÅ›ci podzielÄ™ siÄ™ wÅ‚asnymi doÅ›wiadczeniami "z produkcji" na przestrzeni caÅ‚ego kursu AI Devs. ChciaÅ‚bym jednak podkreÅ›liÄ‡, Å¼e nie na wszystkie pytania mamy odpowiedzi (nie tylko jako twÃ³rcy kursu, ale nawet OpenAI nie ma rozwiÄ…zaÅ„ na np. prompt injection).

PowyÅ¼sze punkty mogÄ… pozostawiÄ‡ CiÄ™ z wraÅ¼eniem, Å¼e jakiekolwiek zastosowanie LLM w kodzie produkcyjnym jest niemoÅ¼liwe. Nie jest to prawda i z powodzeniem LLM sprawdzÄ…Â siÄ™Â do: 

- ZastosowaÅ„ wewnÄ™trznych, np. narzÄ™dzi obsÅ‚ugiwanych przez osoby posiadajÄ…ce wiedzÄ™ na temat pracy z nimi.
- Systemach ograniczajÄ…cych dowolnoÅ›Ä‡ wprowadzanych danych i sposobu prezentowania odpowiedzi. CzÄ™sto wiÄ…Å¼e siÄ™ to z zastosowaniem AI "w tle". PrzykÅ‚adem moÅ¼e byÄ‡ przycisk "dopasuj kolor z AI", ktÃ³ry przeanalizuje obraz i wygeneruje dla niego paletÄ™ kolorÃ³w zgodnie ze zdefiniowanÄ… instrukcjÄ….
- FunkcjonalnoÅ›ciach stanowiÄ…cych wsparcie, niepeÅ‚niÄ…cych krytycznej roli oraz realizujÄ…cych jasno zdefiniowany proces, ktÃ³ry Å‚atwo monitorowaÄ‡. PrzykÅ‚adem moÅ¼e byÄ‡ wzbogacanie bÄ…dÅº klasyfikowanie treÅ›ci lub zaawansowane mechanizmy sugerujÄ…ce treÅ›ci na podstawie dopasowaÅ„ niemoÅ¼liwych (bÄ…dÅº trudnych) do zrealizowania z pomocÄ… kodu.
- WdroÅ¼eniach uwzglÄ™dniajÄ…cych trenowanie i/lub fine-tuning modeli, w celu wyspecjalizowania ich w bardzo konkretnych zadaniach.

Ostatecznie nikt nie zabrania peÅ‚nego, produkcyjnego zastosowania LLM. Scenariusze zarysowane powyÅ¼ej moÅ¼na do pewnego stopnia adresowaÄ‡ lub zgodziÄ‡ siÄ™ na kompromisy. Tym bardziej, Å¼e wiele problemÃ³w, ktÃ³re widzimy dzisiaj, niebawem mogÄ… caÅ‚kowicie zniknÄ…Ä‡. PrzykÅ‚adem moÅ¼e byÄ‡ kwestia prywatnoÅ›ci danych, ktÃ³rÄ… teraz moÅ¼na zaadresowaÄ‡ poprzez plany Enterprise czy modele OpenSource. Zamiast czekaÄ‡ na gotowe rozwiÄ…zania, moÅ¼na juÅ¼ teraz zdobywaÄ‡ doÅ›wiadczenie, ktÃ³re okaÅ¼e siÄ™ przydatne w przyszÅ‚oÅ›ci.

## Zadanie praktyczne

#aidevs_2